{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c8b2a2-b8c8-43b5-a817-875ded448ed9",
   "metadata": {},
   "source": [
    "# Evaluating BEIR with Fess\n",
    "\n",
    "## Introduction\n",
    "This notebook provides a simple and straightforward example of how to evaluate retrieval models from the BEIR benchmark using Fess.\n",
    "\n",
    "## What is BEIR?\n",
    "BEIR (Benchmark for Evaluation of Information Retrieval) is a heterogeneous benchmark designed for zero-shot evaluation of information retrieval models. BEIR contains 9 diverse retrieval tasks and 17 different datasets, allowing for comprehensive evaluation of state-of-the-art retrieval models in a zero-shot setup.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fde0dd-2009-47f1-b4e9-9fc077922237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset = os.getenv(\"BEIR_DATASET\", \"scifact\")\n",
    "fess_dir = os.getenv(\"FESS_DIR\", \"fess\")\n",
    "dataset_dir = os.getenv(\"DATASET_DIR\", os.path.join(os.getcwd(), \"datasets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedda15d-7e91-4560-be1d-e45762053a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the beir PyPI package\n",
    "!pip list | grep beir || pip install beir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9e28f-178e-4463-be93-52aca8fd0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir import util, LoggingHandler\n",
    "\n",
    "import logging\n",
    "import pathlib, os\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d5b31-7a76-4f7b-95a9-614f17a64ab6",
   "metadata": {},
   "source": [
    "## BEIR Datasets\n",
    "\n",
    "BEIR contains 17 diverse datasets overall. You can view all the datasets (14 downloadable) with the link below:\n",
    "\n",
    "[``https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/``](https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/)\n",
    "\n",
    "Please refer GitHub page to evaluate on other datasets (3 of them).\n",
    "\n",
    "\n",
    "We include the following datasets in BEIR:\n",
    "\n",
    "| Dataset   | Website| BEIR-Name | Domain     | Relevancy| Queries  | Documents | Avg. Docs/Q | Download | \n",
    "| -------- | -----| ---------| ----------- | ---------| ---------| --------- | ------| ------------| \n",
    "| MSMARCO    | [``Homepage``](https://microsoft.github.io/msmarco/)| ``msmarco`` | Misc.       |  Binary  |  6,980   |  8.84M     |    1.1 | Yes |  \n",
    "| TREC-COVID |  [``Homepage``](https://ir.nist.gov/covidSubmit/index.html)| ``trec-covid``| Bio-Medical |  3-level|50|  171K| 493.5 | Yes | \n",
    "| NFCorpus   | [``Homepage``](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/) | ``nfcorpus``  | Bio-Medical |  3-level |  323     |  3.6K     |  38.2 | Yes |\n",
    "| BioASQ     | [``Homepage``](http://bioasq.org) | ``bioasq``| Bio-Medical |  Binary  |   500    |  14.91M    |  8.05 | No | \n",
    "| NQ         | [``Homepage``](https://ai.google.com/research/NaturalQuestions) | ``nq``| Wikipedia   |  Binary  |  3,452   |  2.68M  |  1.2 | Yes | \n",
    "| HotpotQA   | [``Homepage``](https://hotpotqa.github.io) | ``hotpotqa``| Wikipedia   |  Binary  |  7,405   |  5.23M  |  2.0 | Yes |\n",
    "| FiQA-2018  | [``Homepage``](https://sites.google.com/view/fiqa/) | ``fiqa``    | Finance     |  Binary  |  648     |  57K    |  2.6 | Yes | \n",
    "| Signal-1M (RT) | [``Homepage``](https://research.signal-ai.com/datasets/signal1m-tweetir.html)| ``signal1m`` | Twitter     |  3-level  |   97   |  2.86M  |  19.6 | No |\n",
    "| TREC-NEWS  | [``Homepage``](https://trec.nist.gov/data/news2019.html) | ``trec-news``    | News     |  5-level  |   57    |  595K    |  19.6 | No |\n",
    "| ArguAna    | [``Homepage``](http://argumentation.bplaced.net/arguana/data) | ``arguana`` | Misc.       |  Binary  |  1,406     |  8.67K    |  1.0 | Yes |\n",
    "| Touche-2020| [``Homepage``](https://webis.de/events/touche-20/shared-task-1.html) | ``webis-touche2020``| Misc.       |  6-level  |  49     |  382K    |  49.2 |  Yes |\n",
    "| CQADupstack| [``Homepage``](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/) | ``cqadupstack``| StackEx.      |  Binary  |  13,145 |  457K  |  1.4 |  Yes |\n",
    "| Quora| [``Homepage``](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs) | ``quora``| Quora  | Binary  |  10,000     |  523K    |  1.6 |  Yes | \n",
    "| DBPedia | [``Homepage``](https://github.com/iai-group/DBpedia-Entity/) | ``dbpedia-entity``| Wikipedia |  3-level  |  400    |  4.63M    |  38.2 |  Yes | \n",
    "| SCIDOCS| [``Homepage``](https://allenai.org/data/scidocs) | ``scidocs``| Scientific |  Binary  |  1,000     |  25K    |  4.9 |  Yes | \n",
    "| FEVER| [``Homepage``](http://fever.ai) | ``fever``| Wikipedia     |  Binary  |  6,666     |  5.42M    |  1.2|  Yes | \n",
    "| Climate-FEVER| [``Homepage``](http://climatefever.ai) | ``climate-fever``| Wikipedia |  Binary  |  1,535     |  5.42M |  3.0 |  Yes |\n",
    "| SciFact| [``Homepage``](https://github.com/allenai/scifact) | ``scifact``| Scientific |  Binary  |  300     |  5K    |  1.1 |  Yes |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237de5a0-a01a-4694-8507-9126f50c4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from beir import util\n",
    "\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "data_path = util.download_and_unzip(url, dataset_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be071025-54f4-4106-81b2-ef68e0dd29a8",
   "metadata": {},
   "source": [
    "## Folder Structure of any BEIR dataset\n",
    "\n",
    "* scifact/\n",
    "    * corpus.jsonl \n",
    "    * queries.jsonl \n",
    "    * qrels/\n",
    "        * train.tsv\n",
    "        * dev.tsv\n",
    "        * test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b07be6-1915-4ad9-8136-720a35a77d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls datasets/{dataset}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d4f69-10f7-46b6-9505-a3d5f9c6f598",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021798a-0bf3-4ead-b76d-0809f219a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "data_path = f\"{dataset_dir}/{dataset}\"\n",
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\") # or split = \"train\" or \"dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6d3bb-cd9f-49b9-b191-b2519281ab27",
   "metadata": {},
   "source": [
    "## Lexical Retrieval using BM25 (Fess)\n",
    "\n",
    "### Run the Fess instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a22780-0b54-4797-b454-180eeb765469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$fess_dir\"\n",
    "\n",
    "cd $1\n",
    "docker compose -f compose.yaml up -d\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f1d7b-56f2-4f5f-a109-6c4f3b75097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "count=0\n",
    "while true ; do\n",
    "    status=$(curl -w '%{http_code}\\n' -s -o /dev/null \"http://localhost:8080/api/v1/health\")\n",
    "    if [[ x\"${status}\" = x200 ]] ; then\n",
    "        break\n",
    "    fi\n",
    "    if [[ ${count} -gt 60 ]] ; then\n",
    "        echo \"timeout\"\n",
    "        break\n",
    "    fi\n",
    "    sleep 1\n",
    "    count=$((count + 1))\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf231df4-f075-4212-a3d3-277246bdeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir_fess.retrieval.search.lexical import FessSearch\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "#### Provide parameters for elastic-search\n",
    "hostname = \"http://localhost:8080\"\n",
    "initialize = True # True, will delete existing index with same name and reindex all documents\n",
    "access_token = \"CHANGEME\"\n",
    "k_values = [1, 3, 5, 10, 50, 100]\n",
    "\n",
    "model = FessSearch(index_name=dataset, hostname=hostname, access_token=access_token, initialize=initialize)\n",
    "retriever = EvaluateRetrieval(model, k_values=k_values)\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f7bdb-1ab7-4a88-b587-d1eed17421e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5abdd-556d-4f6e-9736-ac3f453bc4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ndcg = pd.DataFrame(list(ndcg.items()), columns=['Metric', 'Value'])\n",
    "df_map = pd.DataFrame(list(_map.items()), columns=['Metric', 'Value'])\n",
    "df_recall = pd.DataFrame(list(recall.items()), columns=['Metric', 'Value'])\n",
    "df_precision = pd.DataFrame(list(precision.items()), columns=['Metric', 'Value'])\n",
    "\n",
    "# 縦に結合\n",
    "df = pd.concat([df_ndcg, df_map, df_recall, df_precision], ignore_index=True)\n",
    "df[\"DataSet\"] = dataset\n",
    "df[\"Target\"] = fess_dir\n",
    "df = df[[\"DataSet\", \"Target\", \"Metric\", \"Value\"]]\n",
    "print(df.to_markdown(index=False))\n",
    "df.to_csv(f\"results/{dataset}-{fess_dir}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bac710-a233-45ae-ac8a-7a63a1d98204",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$fess_dir\"\n",
    "\n",
    "cd $1\n",
    "docker compose -f compose.yaml down\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3e957-dc61-4fcf-a91f-6b4ea8964ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
